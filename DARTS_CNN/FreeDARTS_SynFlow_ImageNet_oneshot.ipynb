{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils\n",
    "import logging\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dset\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from model_search_imagenet import Network\n",
    "from architect import Architect\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : FreeDARTS_SynFlow_ImageNet_oneshot-exp-seed-0-20211118-062122\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(\"imagenet\")\n",
    "parser.add_argument('--workers', type=int, default=4, help='number of workers to load dataset')\n",
    "parser.add_argument('--data', type=str, default='/tmp/cache/', help='location of the data corpus')\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='batch size')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.5, help='init learning rate')\n",
    "parser.add_argument('--learning_rate_min', type=float, default=0.0, help='min learning rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "parser.add_argument('--weight_decay', type=float, default=3e-4, help='weight decay')\n",
    "parser.add_argument('--report_freq', type=float, default=50, help='report frequency')\n",
    "parser.add_argument('--epochs', type=int, default=50, help='num of training epochs')\n",
    "parser.add_argument('--init_channels', type=int, default=48, help='num of init channels')\n",
    "parser.add_argument('--layers', type=int, default=14, help='total number of layers')\n",
    "parser.add_argument('--model_path', type=str, default='saved_models', help='path to save the model')\n",
    "parser.add_argument('--cutout', action='store_true', default=False, help='use cutout')\n",
    "parser.add_argument('--cutout_length', type=int, default=16, help='cutout length')\n",
    "parser.add_argument('--drop_path_prob', type=float, default=0.4, help='drop path probability')\n",
    "parser.add_argument('--save', type=str, default='/tmp/checkpoints/', help='experiment name')\n",
    "parser.add_argument('--seed', type=int, default=0, help='random seed')\n",
    "parser.add_argument('--grad_clip', type=float, default=5, help='gradient clipping')\n",
    "parser.add_argument('--unrolled', action='store_true', default=False, help='use one-step unrolled validation loss')\n",
    "parser.add_argument('--arch_learning_rate', type=float, default=6e-3, help='learning rate for arch encoding')\n",
    "parser.add_argument('--arch_weight_decay', type=float, default=1e-3, help='weight decay for arch encoding')\n",
    "parser.add_argument('--begin', type=int, default=35, help='batch size')\n",
    "\n",
    "parser.add_argument('--tmp_data_dir', type=str, default='/home/mzhang3/Data/', help='temp data dir')\n",
    "parser.add_argument('--note', type=str, default='try', help='note for this run')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "args.save = 'FreeDARTS_SynFlow_ImageNet_oneshot-exp-seed-{}-{}'.format(args.seed, time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "utils.create_exp_dir(args.save, scripts_to_save=glob.glob('*.py'))\n",
    "log_format = '%(asctime)s %(message)s'\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO,\n",
    "    format=log_format, datefmt='%m/%d %I:%M:%S %p')\n",
    "fh = logging.FileHandler(os.path.join(args.save, 'log.txt'))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "\n",
    "data_dir = os.path.join(args.tmp_data_dir, 'imagenet')   \n",
    "CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning_func(model, a_optimizer, criterion, optimizer, lr):\n",
    "    objs = utils.AvgrageMeter()\n",
    "    top1 = utils.AvgrageMeter()\n",
    "    top5 = utils.AvgrageMeter()\n",
    "    \n",
    "    ####-------------set \\theta abs\n",
    "    for name, param in model.state_dict().items():\n",
    "        param.abs_()\n",
    "    ####-------------set \\theta abs    \n",
    "    #model._arch_parameters[0].data=abs(model._arch_parameters[0].data)\n",
    "   # model._arch_parameters[1].data=abs(model._arch_parameters[1].data)\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    a_optimizer.zero_grad()  \n",
    "\n",
    "    input_dim = list([3,224,224])##############get the input shape\n",
    "    inputs = torch.ones([1] + input_dim).float().cuda(non_blocking=True)\n",
    "    logits = model(inputs)        \n",
    "\n",
    "    arch_loss = torch.sum(logits)\n",
    "    arch_loss.backward()     \n",
    "\n",
    "    #a_optimizer.step()         \n",
    "    print(arch_loss)\n",
    "\n",
    "\n",
    "    norm_arch_pruned= abs(model._arch_parameters[0].data*model._arch_parameters[0].grad.data)\n",
    "    reduce_arch_pruned= abs(model._arch_parameters[1].data*model._arch_parameters[1].grad.data)\n",
    "        \n",
    "\n",
    "\n",
    "    return norm_arch_pruned, reduce_arch_pruned\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from operations import *\n",
    "from torch.autograd import Variable\n",
    "from genotypes import PRIMITIVES\n",
    "from genotypes import Genotype\n",
    "\n",
    "\n",
    "def synflow_genotype(norm_arch_synflow,redu_arch_synflow):\n",
    "    def _parse(weights):\n",
    "        gene = []\n",
    "        n = 2\n",
    "        start = 0\n",
    "        for i in range(4):\n",
    "            end = start + n\n",
    "            W = weights[start:end].copy()\n",
    "            edges = sorted(range(i + 2), key=lambda x: -max(W[x][k] for k in range(len(W[x])) if k != PRIMITIVES.index('none')))[:2]\n",
    "            for j in edges:\n",
    "                k_best = None\n",
    "                for k in range(len(W[j])):\n",
    "                    if k != PRIMITIVES.index('none'):\n",
    "                        if k_best is None or W[j][k] > W[j][k_best]:\n",
    "                            k_best = k\n",
    "                gene.append((PRIMITIVES[k_best], j))\n",
    "            start = end\n",
    "            n += 1\n",
    "        return gene\n",
    "\n",
    "    #gene_normal = _parse(F.softmax(self.alphas_normal, dim=-1).data.cpu().numpy())\n",
    "    #gene_reduce = _parse(F.softmax(self.alphas_reduce, dim=-1).data.cpu().numpy())\n",
    "    gene_normal = _parse(norm_arch_synflow.cpu().numpy())\n",
    "    gene_reduce = _parse(redu_arch_synflow.cpu().numpy())\n",
    "    \n",
    "    \n",
    "    concat = range(2, 6)\n",
    "    genotype = Genotype(\n",
    "      normal=gene_normal, normal_concat=concat,\n",
    "      reduce=gene_reduce, reduce_concat=concat\n",
    "    )\n",
    "\n",
    "    return genotype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/18 06:21:23 AM args = Namespace(arch_learning_rate=0.006, arch_weight_decay=0.001, batch_size=1, begin=35, cutout=False, cutout_length=16, data='/tmp/cache/', drop_path_prob=0.4, epochs=50, grad_clip=5, init_channels=48, layers=14, learning_rate=0.5, learning_rate_min=0.0, model_path='saved_models', momentum=0.9, note='try', report_freq=50, save='FreeDARTS_SynFlow_ImageNet_oneshot-exp-seed-0-20211118-062122', seed=0, tmp_data_dir='/home/mzhang3/Data/', unrolled=False, weight_decay=0.0003, workers=4)\n",
      "11/18 06:21:25 AM param size = 25.512016MB\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    logging.info('no gpu device available')\n",
    "    sys.exit(1)\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "#torch.cuda.set_device(args.gpu)\n",
    "cudnn.benchmark = True\n",
    "torch.manual_seed(args.seed)\n",
    "cudnn.enabled=True\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "#logging.info('gpu device = %d' % args.gpu)\n",
    "logging.info(\"args = %s\", args)\n",
    "#dataset_dir = '/cache/'\n",
    "#pre.split_dataset(dataset_dir)\n",
    "#sys.exit(1)\n",
    "# dataset prepare\n",
    "traindir = os.path.join(data_dir, 'train')\n",
    "valdir = os.path.join(data_dir,  'val')\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                       std=[0.229, 0.224, 0.225])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.cuda()\n",
    "#dataset split     \n",
    "\n",
    "model = Network(args.init_channels, CLASSES, args.layers, criterion)\n",
    "##model = torch.nn.DataParallel(model)\n",
    "model = model.cuda()\n",
    "logging.info(\"param size = %fMB\", utils.count_parameters_in_MB(model))\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    args.learning_rate,\n",
    "    momentum=args.momentum,\n",
    "    weight_decay=args.weight_decay)\n",
    "optimizer_a = torch.optim.Adam(model.arch_parameters(),\n",
    "           lr=args.arch_learning_rate, betas=(0.5, 0.999), \n",
    "           weight_decay=args.arch_weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, float(args.epochs), eta_min=args.learning_rate_min)\n",
    "\n",
    "    #architect = Architect(model, args)\n",
    "lr=args.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mzhang3/anaconda3/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "/data/mzhang3/anaconda3/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:484: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  \"please use `get_last_lr()`.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17.6584, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "11/18 06:21:25 AM Pruning cost 0.7 s.\n",
      "11/18 06:21:25 AM Searched architecture------------------\n",
      "11/18 06:21:25 AM Genotype(normal=[('dil_conv_5x5', 0), ('dil_conv_5x5', 1), ('dil_conv_3x3', 1), ('dil_conv_3x3', 0), ('sep_conv_3x3', 2), ('dil_conv_5x5', 1), ('sep_conv_5x5', 0), ('sep_conv_3x3', 2)], normal_concat=range(2, 6), reduce=[('dil_conv_3x3', 0), ('max_pool_3x3', 1), ('dil_conv_3x3', 0), ('skip_connect', 1), ('sep_conv_5x5', 3), ('dil_conv_5x5', 0), ('sep_conv_5x5', 2), ('avg_pool_3x3', 0)], reduce_concat=range(2, 6))\n",
      "11/18 06:21:25 AM ---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epoch=0\n",
    "\n",
    "scheduler.step()\n",
    "current_lr = scheduler.get_lr()[0]\n",
    "\n",
    "start_time= time.time()\n",
    "\n",
    "norm_arch_pruned, reduce_arch_pruned = pruning_func(model, optimizer_a, criterion, optimizer, lr)\n",
    "\n",
    "\n",
    "search_time = time.time() - start_time\n",
    "\n",
    "logging.info('Pruning cost {:.1f} s.'.format(search_time))\n",
    "\n",
    "\n",
    "genotype=synflow_genotype(norm_arch_pruned,reduce_arch_pruned)\n",
    "\n",
    "logging.info('Searched architecture------------------')\n",
    "logging.info(genotype)\n",
    "logging.info('---------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
